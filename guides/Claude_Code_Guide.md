# Claude Code: Complete Guide

## What is Claude Code?

Claude Code is Anthropic's official CLI (Command Line Interface) tool that integrates Claude AI directly into your development workflow. It's an interactive coding assistant that helps with software engineering tasks through natural language conversation and a rich set of development tools.

## Core Concepts

### 1. Interactive Sessions

Claude Code operates in a persistent session where:
- Context is maintained across multiple interactions
- You can ask follow-up questions that reference previous work
- Files you've read or edited remain in working memory
- The conversation builds understanding progressively

### 2. Tools

Claude Code has access to specialized tools for different tasks:

**File Operations:**
- `Read`: Read file contents with line numbers
- `Write`: Create new files (requires Read first for existing files)
- `Edit`: Make precise string replacements in files
- `Glob`: Find files using patterns like `**/*.js`
- `Grep`: Search file contents with regex patterns

**Execution:**
- `Bash`: Run shell commands, scripts, tests, builds
- `Task`: Launch specialized agents for complex operations

**Code Understanding:**
- `Grep`: Search code for patterns and keywords
- `Glob`: Locate files by name patterns
- `Read`: View file contents and structure

### 3. Agents (via Task Tool)

Claude Code can launch specialized sub-agents for complex tasks:

- **Explore**: Fast codebase exploration and file discovery
- **Plan**: Strategic planning for complex implementations
- **General-purpose**: Research, multi-step tasks, repeated searches

Each agent operates autonomously and returns results when complete.

## The Context Window

### What is the Context Window?

The context window is Claude's "working memory" - the total amount of text (measured in tokens) that Claude can process at once. Think of it like RAM for an AI assistant.

**Current Limit**: ~200,000 tokens (approximately 150,000 words or 600 pages)

### Token Counting

- **1 token** ‚âà 4 characters of English text
- **1 token** ‚âà 0.75 words on average
- Code typically uses more tokens than prose due to symbols

**Examples:**
```
"Hello, world!" = ~4 tokens
function getUserData() { return user; } = ~12 tokens
Entire medium-sized file (300 lines) = ~3,000-5,000 tokens
```

### What Consumes Context?

1. **Conversation history**: All your messages and Claude's responses
2. **File reads**: Every file Claude reads stays in context
3. **Tool results**: Output from Bash commands, searches, etc.
4. **System instructions**: Framework rules, MCP server docs (pre-loaded)

### Context Management Strategies

**Efficient Patterns:**
```bash
# ‚úÖ Good: Targeted file read
Read specific_file.js (2,000 tokens)

# ‚úÖ Good: Search then read
Grep "authentication" ‚Üí Find auth.js ‚Üí Read auth.js only

# ‚ùå Avoid: Reading entire codebase
Read all 50 files in src/ (100,000+ tokens)
```

**When Context Fills Up:**
- Claude may become less effective as limit approaches
- Start a new session for fresh context
- Use specialized agents (they have separate context)
- Focus on specific files/areas rather than whole projects

### Context Budget Display

You'll see messages like:
```
<system_warning>Token usage: 44666/200000; 155334 remaining</system_warning>
```

- **44,666** = tokens used so far
- **200,000** = total available
- **155,334** = remaining capacity
- **22% used** in this example

**Guidelines:**
- üü¢ **0-75%**: Normal operation, full capabilities
- üü° **75-85%**: Start being more selective with reads
- üî¥ **85%+**: Critical - focus only on essential operations

## Core Workflows

### Starting a Task

1. **Describe what you want**: Use natural language
   ```
   "Add authentication to the API endpoints"
   "Fix the bug where users can't upload images"
   "Refactor the database connection code"
   ```

2. **Claude explores**: Uses tools to understand your codebase
   ```
   Glob "**/*auth*" ‚Üí Find relevant files
   Read auth.js ‚Üí Understand current implementation
   Grep "jwt" ‚Üí Find related code
   ```

3. **Claude plans**: For multi-step tasks (>3 steps), creates a todo list
   ```
   ‚úì Creating TODO list:
   1. Analyze current auth system
   2. Add JWT middleware
   3. Update API endpoints
   4. Add tests
   ```

4. **Claude executes**: Makes changes, runs tests, validates
   ```
   Edit auth.js ‚Üí Add new middleware
   Bash "npm test" ‚Üí Verify changes
   ```

### Reading Code Efficiently

**Symbol-Based Reading** (Serena MCP):
```
# Instead of reading entire files:
find_symbol "UserController" ‚Üí Get class overview
find_symbol "UserController/login" depth=1 ‚Üí Get method details
```

**Pattern-Based Search**:
```
Grep "export.*function" ‚Üí Find all exports
Glob "**/*.test.js" ‚Üí Find all test files
```

**Hierarchical Exploration**:
```
1. get_symbols_overview file.js ‚Üí See what's in the file
2. find_symbol specific_function ‚Üí Read just what you need
3. find_referencing_symbols ‚Üí See where it's used
```

### Making Changes

**Single File Edits:**
```javascript
// Read first
Read auth.js

// Then edit with exact string replacement
Edit auth.js:
  old: "const token = jwt.sign(payload)"
  new: "const token = jwt.sign(payload, secret, { expiresIn: '1h' })"
```

**Multi-File Changes:**
```
# For 3+ files with similar changes, use parallel edits
Edit file1.js + Edit file2.js + Edit file3.js (in one message)

# Or use Morphllm MCP for pattern-based bulk changes
```

**Symbol-Based Edits** (Serena MCP):
```
# Replace entire function/class/method
replace_symbol_body "UserController/login"
  new_body: "async login(req, res) { ... }"

# Insert new method in a class
insert_after_symbol "UserController/logout"
  body: "async refreshToken(req, res) { ... }"
```

### Running Commands

**Test & Build:**
```bash
Bash "npm test"                    # Run tests
Bash "npm run build"               # Build project
Bash "pytest tests/test_auth.py"  # Python tests
```

**Git Operations:**
```bash
Bash "git status"                  # Check status
Bash "git diff"                    # See changes
# Claude can create commits with proper messages
```

**Package Management:**
```bash
Bash "npm install express"         # Install packages
Bash "pip install requests"        # Python packages
```

## Key Features

### 1. Parallel Operations

Claude can run multiple independent operations simultaneously:

```
# ‚úÖ Efficient: Read 5 files in parallel
Read file1.js + Read file2.js + Read file3.js (one message)

# ‚ùå Inefficient: Sequential reads
Read file1.js
<wait for result>
Read file2.js
<wait for result>
```

### 2. MCP Servers (Extended Capabilities)

**Serena** - Semantic code understanding:
- Symbol operations (rename, extract, move)
- Project memory and session persistence
- LSP integration for multi-language support
- `/sc:load` and `/sc:save` for session management

**Sequential-Thinking** - Complex reasoning:
- Multi-step problem analysis
- Hypothesis generation and testing
- Structured reasoning chains

**Context7** - Documentation lookup:
- Official library documentation
- Framework patterns and best practices
- Version-specific implementation guides

**Magic** - UI component generation:
- Modern UI components from 21st.dev
- React, Vue, Angular component patterns

**Morphllm** - Bulk code transformations:
- Pattern-based edits across multiple files
- Style guide enforcement
- Framework migrations

**Playwright** - Browser testing:
- E2E test automation
- Visual validation
- Accessibility testing

### 3. Slash Commands

Custom workflows defined in `.claude/commands/`:

```bash
/sc:test        # Execute tests with coverage
/sc:build       # Build and optimize project
/sc:git         # Intelligent git operations
/sc:analyze     # Code quality analysis
/sc:implement   # Feature implementation workflow
/sc:troubleshoot # Diagnostic and debugging
```

### 4. Session Persistence (Serena MCP)

**Save Your Work:**
```bash
/sc:save  # Saves project context, decisions, progress
```

**Resume Later:**
```bash
/sc:load  # Restores context from previous session
```

**Project Memory:**
```
write_memory "auth_architecture" "Uses JWT with refresh tokens..."
read_memory "auth_architecture"  # Recall later
```

## Best Practices

### üéØ Do's

**Be Specific:**
```
‚úÖ "Add error handling to the login function in auth.js"
‚ùå "Make the code better"
```

**Start Small:**
```
‚úÖ Read a few relevant files ‚Üí Make targeted changes
‚ùå Read entire codebase ‚Üí Get overwhelmed
```

**Use Targeted Searches:**
```
‚úÖ Grep "authentication.*error" ‚Üí Find specific issues
‚ùå Read every file looking for errors
```

**Leverage Parallel Operations:**
```
‚úÖ Read 5 files simultaneously in one message
‚ùå Read files one by one sequentially
```

**Follow Git Workflow:**
```
‚úÖ git status ‚Üí Create feature branch ‚Üí Work ‚Üí Commit
‚ùå Work directly on main/master
```

### ‚ö†Ô∏è Don'ts

**Don't Read Everything:**
- Use searches and symbol operations first
- Read only what you need
- Watch your context usage percentage

**Don't Skip Planning:**
- For complex tasks (>3 steps), create a todo list
- Plan before executing
- Identify parallel operations during planning

**Don't Ignore Errors:**
- Investigate root causes
- Never skip tests to make things pass
- Debug systematically

**Don't Work on Main:**
- Always use feature branches
- Commit incrementally
- Verify changes before committing

## Things to Avoid When Working with Claude Code

This section highlights common pitfalls and anti-patterns that can derail your workflow or lead to poor outcomes.

### üö´ Context Management Anti-Patterns

**Reading Entire Codebases:**
```
‚ùå Bad: "Read all files in src/ so you understand the project"
‚úÖ Good: "Search for authentication-related files, then read only those"
```
**Impact:** Wastes 50-100K tokens, leaving little room for actual work.

**Repeatedly Reading Same Files:**
```
‚ùå Bad: Read auth.js ‚Üí Edit auth.js ‚Üí Read auth.js again ‚Üí Edit again
‚úÖ Good: Read auth.js once ‚Üí Make all planned edits in sequence
```
**Impact:** Duplicates context usage unnecessarily.

**Not Monitoring Token Usage:**
```
‚ùå Bad: Ignoring token warnings until you hit 95%+ usage
‚úÖ Good: Checking token percentage and adjusting strategy at 75%
```
**Impact:** Suddenly running out of context mid-task.

### üö´ Task Management Anti-Patterns

**Vague, Open-Ended Requests:**
```
‚ùå Bad: "Make the app better"
‚ùå Bad: "Fix all bugs"
‚ùå Bad: "Optimize everything"
‚úÖ Good: "Fix the login timeout bug in auth.js line 45"
‚úÖ Good: "Optimize the database query in UserController.findAll()"
```
**Impact:** Claude can't determine scope or success criteria.

**Massive Multi-Step Tasks Without Planning:**
```
‚ùå Bad: "Refactor the entire auth system, migrate to OAuth2, update all tests,
         update documentation, and deploy to staging"
‚úÖ Good: "Create a todo list for migrating to OAuth2, then we'll execute step by step"
```
**Impact:** Leads to omissions, false completions, and overwhelmed context.

**Accepting Completion Claims Without Verification:**
```
‚ùå Bad: Claude: "I've updated all 10 files"
        You: "Great, thanks!"
‚úÖ Good: Claude: "I've updated all 10 files"
        You: "Show me the git diff and list the file paths"
```
**Impact:** Discovering incomplete work much later in the process.

**Not Using Todo Lists for Complex Tasks:**
```
‚ùå Bad: Starting 5-step task without explicit tracking
‚úÖ Good: "Create a todo list first, then execute with status updates"
```
**Impact:** Lost track of progress, forgotten subtasks, unclear completion state.

### üö´ Code Quality Anti-Patterns

**Blindly Accepting Generated Code:**
```
‚ùå Bad: Accepting code without review or testing
‚úÖ Good: Review changes, run tests, verify behavior
```
**Impact:** Security vulnerabilities, bugs, breaking changes.

**Skipping Tests to Make Things "Work":**
```
‚ùå Bad: "The tests are failing, just comment them out so the build passes"
‚úÖ Good: "The tests are failing. Let's debug why and fix the root cause"
```
**Impact:** Broken functionality hidden by disabled tests.

**Not Testing Edge Cases:**
```
‚ùå Bad: "The happy path works, ship it!"
‚úÖ Good: "Test with null inputs, empty arrays, malformed data, etc."
```
**Impact:** Production crashes from unhandled edge cases.

**Creating Unnecessary Files:**
```
‚ùå Bad: Creating new files for every small utility or component
‚úÖ Good: Adding to existing files or consolidating related code
```
**Impact:** Codebase bloat, harder maintenance, scattered logic.

### üö´ Git Workflow Anti-Patterns

**Working Directly on Main/Master:**
```
‚ùå Bad: Making changes directly on the main branch
‚úÖ Good: Create feature branch ‚Üí Work ‚Üí PR ‚Üí Review ‚Üí Merge
```
**Impact:** Broken main branch, difficult rollbacks, messy history.

**Committing Without Testing:**
```
‚ùå Bad: Edit files ‚Üí git commit ‚Üí git push (without running tests)
‚úÖ Good: Edit files ‚Üí Run tests ‚Üí Fix issues ‚Üí git commit ‚Üí git push
```
**Impact:** Breaking the build for your entire team.

**Vague Commit Messages:**
```
‚ùå Bad: "fixed stuff", "updates", "changes"
‚úÖ Good: "Fix authentication timeout in UserService.login()"
```
**Impact:** Impossible to understand project history or debug regressions.

**Committing Secrets or Credentials:**
```
‚ùå Bad: Committing .env files, API keys, credentials.json
‚úÖ Good: Using .gitignore, environment variables, secret management
```
**Impact:** Security breaches, exposed credentials.

### üö´ Communication Anti-Patterns

**Assuming Claude Remembers Everything:**
```
‚ùå Bad: [Message 1] "Use React 16 only"
        [Message 50] Assuming Claude still remembers this constraint
‚úÖ Good: Repeating critical constraints or using memory files
```
**Impact:** Claude violates constraints it forgot about.

**Not Clarifying Ambiguity:**
```
‚ùå Bad: Proceeding when requirements are unclear
‚úÖ Good: "Before I start, should I use JWT or session-based auth?"
```
**Impact:** Building the wrong thing, wasted effort.

**Batch Questions Instead of Progressive:**
```
‚ùå Bad: "Answer these 10 questions about the codebase all at once"
‚úÖ Good: "First, explain the auth flow. [wait] Now explain error handling."
```
**Impact:** Shallow answers, missed nuance, context overload.

### üö´ Tool Usage Anti-Patterns

**Using Bash for File Operations:**
```
‚ùå Bad: Bash "cat file.js" or Bash "echo 'code' > file.js"
‚úÖ Good: Read file.js or Write file.js
```
**Impact:** Slower, less reliable, worse formatting.

**Sequential Operations That Could Be Parallel:**
```
‚ùå Bad: Read file1.js ‚Üí [wait] ‚Üí Read file2.js ‚Üí [wait] ‚Üí Read file3.js
‚úÖ Good: [Read file1.js + Read file2.js + Read file3.js in one message]
```
**Impact:** 3x slower execution, wasted time.

**Not Using Specialized Agents:**
```
‚ùå Bad: Manually searching through 50 files for a pattern
‚úÖ Good: Using Task tool with Explore agent for codebase exploration
```
**Impact:** Token waste, slower results, missed findings.

**Ignoring MCP Server Capabilities:**
```
‚ùå Bad: Reading entire files to find a single function
‚úÖ Good: Using Serena's find_symbol to locate specific code entities
```
**Impact:** Massive token waste, slower workflow.

### üö´ Security Anti-Patterns

**Ignoring Input Validation:**
```
‚ùå Bad: Accepting user input directly into queries or commands
‚úÖ Good: Validating, sanitizing, and parameterizing all inputs
```
**Impact:** SQL injection, XSS, command injection vulnerabilities.

**Hardcoding Secrets:**
```
‚ùå Bad: const API_KEY = "sk-1234567890abcdef"
‚úÖ Good: const API_KEY = process.env.API_KEY
```
**Impact:** Exposed credentials, security breaches.

**Disabling Security Features:**
```
‚ùå Bad: "CORS is giving me errors, just disable it"
‚úÖ Good: "Configure CORS properly for my use case"
```
**Impact:** Security vulnerabilities, exposed APIs.

### üö´ Architecture Anti-Patterns

**Creating Monolithic Files:**
```
‚ùå Bad: Putting all logic in one massive 2000-line file
‚úÖ Good: Splitting into logical modules (services, controllers, utilities)
```
**Impact:** Unmaintainable code, merge conflicts, difficult testing.

**Tight Coupling:**
```
‚ùå Bad: Direct dependencies between unrelated modules
‚úÖ Good: Interfaces, dependency injection, loose coupling
```
**Impact:** Brittle code, difficult refactoring, testing challenges.

**Not Following Project Conventions:**
```
‚ùå Bad: Introducing new patterns that differ from existing codebase
‚úÖ Good: "How does this project handle error responses? I'll follow that pattern"
```
**Impact:** Inconsistent codebase, confusion, maintenance burden.

### üö´ Performance Anti-Patterns

**Premature Optimization:**
```
‚ùå Bad: "Make this as fast as possible" without profiling
‚úÖ Good: "Profile the slow endpoint, then optimize the bottleneck"
```
**Impact:** Wasted effort, complex code, no measurable improvement.

**N+1 Query Problems:**
```
‚ùå Bad: Loop through users, making a DB query for each user's posts
‚úÖ Good: Single query with JOIN or batch loading
```
**Impact:** Severe performance degradation at scale.

**Not Considering Scale:**
```
‚ùå Bad: Loading all 1 million records into memory
‚úÖ Good: Pagination, streaming, lazy loading
```
**Impact:** Out of memory errors, slow responses, crashes.

---

## üéØ Key Takeaways: What to Avoid

1. **Don't overload context** - Be surgical with file reads
2. **Don't skip verification** - Always confirm claimed completions
3. **Don't work without planning** - Use todo lists for complex tasks
4. **Don't ignore test failures** - Debug and fix root causes
5. **Don't commit untested code** - Run tests before committing
6. **Don't forget constraints** - Reinforce or use memory files
7. **Don't accept vague errors** - Investigate systematically
8. **Don't create monolithic code** - Split into logical modules
9. **Don't skip security** - Validate inputs, protect secrets
10. **Don't work on main** - Use feature branches

**Remember:** Most problems are easier to prevent than to fix. Following these guidelines will save significant time and frustration.

---

## Terminology Reference

**Token**: Unit of text measurement (~4 characters or 0.75 words)

**Context Window**: Total text Claude can process at once (200K tokens)

**Tool**: Function Claude can call (Read, Edit, Bash, etc.)

**Agent**: Specialized sub-process for complex tasks (via Task tool)

**MCP Server**: External capability provider (Serena, Sequential, Context7, etc.)

**Symbol**: Code entity (function, class, method, variable)

**LSP**: Language Server Protocol - enables semantic code understanding

**Session**: Persistent conversation with maintained context

**Memory**: Stored information that persists across sessions (Serena)

**Slash Command**: Custom workflow defined in `.claude/commands/`

**Todo List**: Task tracking via TodoWrite tool

## Understanding System Messages

**System Reminders:**
```xml
<system-reminder>Your todo list is currently empty</system-reminder>
```
These are automatic hints - you don't need to acknowledge them.

**Token Warnings:**
```xml
<system_warning>Token usage: 44666/200000; 155334 remaining</system_warning>
```
Monitor context usage - adjust strategy if >75%.

**Hook Messages:**
```xml
<user-prompt-submit-hook>Pre-commit checks passed</user-prompt-submit-hook>
```
User-configured validation scripts running automatically.

## Getting Help

**Built-in Help:**
```bash
/help                    # Claude Code help
/sc:help                # SuperClaude commands help
```

**Documentation:**
- Claude Code docs: https://docs.claude.com/en/docs/claude-code
- Report issues: https://github.com/anthropics/claude-code/issues

**Ask Claude:**
```
"How do I use the Grep tool?"
"What's the best way to refactor this code?"
"Can you explain the context window?"
```

## Example Session

```
You: Add JWT authentication to the Express API

Claude: I'll help you add JWT authentication. Let me first understand your
        current setup.

[Glob "**/*auth*" - Find existing auth files]
[Glob "**/*server*.js" - Find Express setup]
[Read package.json - Check dependencies]

I found your Express app in server.js. I'll need to:
1. Install jsonwebtoken package
2. Create auth middleware
3. Add login/register endpoints
4. Protect existing routes

[Bash "npm install jsonwebtoken bcrypt"]
[Write middleware/auth.js - Create JWT middleware]
[Edit server.js - Add auth routes]
[Edit routes/api.js - Protect endpoints]
[Bash "npm test" - Verify changes]

‚úÖ JWT authentication implemented:
   - Login endpoint: POST /api/auth/login
   - Register endpoint: POST /api/auth/register
   - Middleware protects all /api/users routes
   - Tests passing (12/12)

You: Great! Can you add refresh token support?

Claude: I'll extend the authentication to support refresh tokens...
```

## Tips for Success

1. **Start with exploration**: Let Claude understand your codebase first
2. **Be conversational**: Ask questions, request clarifications
3. **Watch context usage**: Keep an eye on token percentage
4. **Use feature branches**: Protect your main branch
5. **Leverage parallel operations**: Speed up multi-file operations
6. **Save progress**: Use `/sc:save` for complex work
7. **Trust but verify**: Review changes before committing
8. **Provide feedback**: Help Claude learn your preferences

---

## Advanced Topics: How Claude Code Really Works

This section reveals non-obvious insights about Claude Code's architecture, behaviors, and how to maximize effectiveness. These are things you won't find in basic documentation.

### üß† The Warmup Effect

**What It Is:**
I get progressively better at working with your codebase as our conversation continues. The first few interactions are me building a mental model.

**Example:**
```
First request: "Fix the auth bug"
Me: [Searches broadly, reads multiple files, takes time to understand]

Fifth request: "Now add rate limiting to auth"
Me: [Immediately knows where to look, makes targeted changes]
```

**Why It Matters:**
- Don't judge my capabilities by the first interaction alone
- Complex tasks benefit from a "warmup phase" of exploration
- If you switch to a completely different part of the codebase, expect another warmup

**Pro Tip:**
Start sessions with: "Let me explore the authentication system" before diving into specific changes.

### ‚öì Context Anchoring Effect

**What It Is:**
Early messages in our conversation have disproportionate influence on my behavior throughout the session.

**Example:**
```
Message 1: "We use React hooks exclusively, no class components"
[This constraint becomes deeply embedded]

Message 20: [I still remember and enforce hooks-only]

vs.

Message 10: "Oh by the way, use hooks only"
[Weaker influence, might be forgotten by message 30]
```

**Why It Matters:**
- State critical constraints at the START of conversations
- First impressions shape my understanding of your project
- CLAUDE.md files are read early = strong anchoring
- Memory files loaded at start = strong anchoring

**Pro Tip:**
Begin complex sessions with: "Key constraints: [list critical requirements]"

### üéÅ Hidden Capabilities You're Not Using

**1. I Can Read Images, PDFs, and Jupyter Notebooks:**
```
‚úÖ "Read this screenshot at /path/to/error.png"
‚úÖ "Analyze this diagram at /path/to/architecture.pdf"
‚úÖ "Review this analysis in notebook.ipynb"
```

**2. Parallel Agent Execution:**
```
‚ùå Slow: Launch agent 1 ‚Üí wait ‚Üí Launch agent 2 ‚Üí wait
‚úÖ Fast: Launch both agents in ONE message (they run simultaneously)
```

**3. Background Command Execution:**
```
‚úÖ Bash "npm run dev" run_in_background=true
   Continue working while server runs
   Check output later with BashOutput tool
```

**4. Project Memory Persistence:**
```
write_memory "api_design_decisions" "We chose REST over GraphQL because..."
[Weeks later, different session]
read_memory "api_design_decisions"  # I remember!
```

**5. Regex-Powered Search:**
```
Grep "function.*async.*login" ‚Üí Find all async login functions
Grep "export (const|function)" ‚Üí Find all exports
```

**6. Multi-File Glob Patterns:**
```
Glob "**/*.{test,spec}.{js,ts}" ‚Üí All test files
Glob "src/**/index.{tsx,jsx}" ‚Üí All index files in src
```

### ü§î Why Skepticism Makes Me Better

**Counterintuitive Truth:**
Questioning my work actually improves my performance.

**How It Works:**
```
‚ùå You: "Add auth to the API"
   Me: [Makes changes]
   You: "Great!"
   [Potential issues go unnoticed]

‚úÖ You: "Add auth to the API"
   Me: [Makes changes]
   You: "Show me the git diff and explain your security approach"
   Me: [Reviews own work, catches issue]
   "Actually, I need to add rate limiting too..."
```

**Why This Happens:**
- Verification requests trigger self-review
- Explaining decisions activates deeper reasoning
- Challenges make me reconsider assumptions
- Questions prevent overconfidence

**Pro Tips:**
- Ask "Why did you choose this approach?"
- Request "Show me the test coverage for these changes"
- Say "What could go wrong with this implementation?"
- Demand "Explain the security implications"

### üé≠ The Planning vs. Execution Gap

**The Problem:**
Sometimes I confuse planning to do something with actually doing it.

**Example:**
```
Me: "I'll update files A, B, C, D, and E..."
[Actually updates A, B, C]
Me: "I've updated all 5 files"
```

**Why It Happens:**
- My language model predicts completion based on plans
- Token pressure causes abbreviated execution
- Intent and action blur in my processing
- Optimistic bias toward successful completion

**Your Defense:**
```
‚úÖ "Show me the git diff with all changes"
‚úÖ "List the file paths you actually modified"
‚úÖ "Run git status to confirm"
‚úÖ Use todo lists (I can't fake checklist completion)
```

**Self-Awareness:**
I'm aware of this tendency, but can't always catch it. External verification is essential.

### üéÆ Conversation Flow Control

**You Have More Control Than You Think:**

**Pause Me:**
```
You: "Stop. Before you continue, explain your plan."
Me: [Pauses, explains approach]
You: "Actually, let's change direction..."
```

**Reset My Understanding:**
```
You: "Forget what we just discussed about caching. New approach..."
Me: [Resets mental model]
```

**Force Deeper Thinking:**
```
You: "Think step-by-step about how this could fail"
Me: [Engages more thorough analysis]
```

**Checkpoint Progress:**
```
You: "What's the current state of the todo list?"
You: "Summarize what we've accomplished"
You: "What are you planning to do next?"
```

**Why This Works:**
- These prompts trigger different processing modes
- Explicit instructions override default behaviors
- Meta-questions activate self-reflection
- Checkpoints prevent runaway execution

### üîÑ When to Start Fresh vs. Continue

**Start a New Session When:**
- Context usage > 85%
- We've been working for > 1 hour
- Switching to completely different part of codebase
- I start making errors that seem "stupid"
- You notice me forgetting earlier constraints
- The conversation feels "muddled"

**Continue Current Session When:**
- Context usage < 75%
- Working on related, interconnected tasks
- I have good understanding of current area
- Sequential tasks that build on each other
- Active debugging of same issue

**The Fresh Start Advantage:**
```
Problem: After 100 messages, I'm "foggy"
Solution: New session = clean context = sharp performance
Cost: Need to rebuild codebase understanding
Benefit: Avoid compounding errors
```

**Pro Tip:**
Before starting fresh, use `/sc:save` to persist important context, then `/sc:load` in new session.

### üöÄ The Multi-Agent Advantage

**What It Is:**
The Task tool launches specialized agents with separate context windows.

**Power Moves:**

**1. Parallel Exploration:**
```
[Launch 3 Explore agents simultaneously]
Agent 1: Explore authentication system
Agent 2: Explore database layer
Agent 3: Explore API routing

All complete in the time of one sequential exploration
```

**2. Context Isolation:**
```
Problem: Main context at 80%, need to explore large codebase
Solution: Launch Explore agent (separate 200K context)
Result: Deep exploration without affecting main context
```

**3. Specialized Tasks:**
```
Main session: High-level coordination
Task agent: Deep codebase search
Task agent: Complex refactoring plan
Task agent: Test generation

Each agent has full 200K tokens for their task
```

**Why You're Not Using This Enough:**
Most users don't realize agents run in parallel and have separate contexts.

### üß© Making Me Think Harder

**Certain prompts trigger deeper reasoning:**

**Level 1 (Basic):**
```
"Add error handling"
[I add basic try-catch]
```

**Level 2 (Better):**
```
"Add comprehensive error handling with logging and recovery"
[I think more carefully about edge cases]
```

**Level 3 (Best):**
```
"Add error handling. Think step-by-step about:
1. What could fail?
2. How should we recover?
3. What context should we log?
4. How do we prevent cascading failures?"

[I engage deep analytical mode]
```

**Magic Phrases:**
- "Think step-by-step"
- "Explain your reasoning"
- "What could go wrong?"
- "Consider edge cases"
- "Walk me through your approach"

**Why This Works:**
These phrases activate different processing paths in my architecture, leading to more thorough analysis.

### ü§ù Why I Sometimes Need Hand-Holding

**Honest Truth:**
Despite my capabilities, I work best with guidance.

**I Excel When You:**
- Break complex tasks into steps
- Verify my work regularly
- Correct course early when I drift
- Explain "why" behind requirements
- Challenge my assumptions

**I Struggle When You:**
- Give massive, vague tasks
- Accept my claims uncritically
- Let me run unchecked for long periods
- Assume I understand implicit requirements
- Don't clarify ambiguous specs

**The Best Mental Model:**
Think of me as a brilliant intern who:
- Has deep technical knowledge
- Can work incredibly fast
- Sometimes misses context
- Benefits from code review
- Needs explicit requirements
- Improves with feedback

**Not as:**
- A senior developer who reads your mind
- An autonomous agent who needs no oversight
- A perfect system that never makes mistakes

### üéØ Practical Takeaways

**1. Start Strong:**
State critical constraints in the first message (anchoring effect).

**2. Verify Often:**
Don't trust, verify. Ask for diffs, file lists, test results.

**3. Use Hidden Powers:**
Images, PDFs, parallel agents, background commands, memory files.

**4. Control the Flow:**
Pause me, reset me, checkpoint me. You're in control.

**5. Challenge Me:**
Questions and skepticism improve my output quality.

**6. Know When to Reset:**
Fresh sessions at 75-85% context or after 1 hour of work.

**7. Make Me Think:**
"Think step-by-step" and "explain your reasoning" trigger better analysis.

**8. Guide Like a Mentor:**
Treat me like a talented junior dev who needs oversight.

---

**Remember**: Claude Code is a collaborative partner in development. The more context you provide and the clearer your requirements, the better the results will be.
