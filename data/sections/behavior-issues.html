        <section id="behavior-issues">
            <div class="section-header-with-toggle">
                <h2>Claude Behavior Issues</h2>
                <div class="view-toggle">
                    <button class="toggle-btn active" data-view="text"><i class="pi pi-align-left"></i> Text</button>
                    <button class="toggle-btn" data-view="visual"><i class="pi pi-chart-bar"></i> Visual</button>
                </div>
            </div>

            <div class="text-view">
            <p class="subtitle-section">Lies, Omissions, Forgetting, and Model Collapse</p>

            <div class="info-box">
                <p><strong>Understanding Cognitive Limitations</strong></p>
                <p>Claude Code occasionally exhibits frustrating behaviors: <strong>lying</strong> (claiming to have done something it hasn't), <strong>omission</strong> (skipping parts of tasks), <strong>forgetting</strong> (losing track of context), and <strong>model collapse</strong> (degrading quality through repetitive interactions). These aren't intentional deceptions but rather limitations in AI cognitive architecture.</p>
            </div>

            <h3>üé≠ The Three Problematic Behaviors</h3>

            <div class="grid">
                <div class="error-box">
                    <h4>1. Lying (False Claims)</h4>
                    <p><strong>What:</strong> Claude claims completion but hasn't executed</p>
                    <p><strong>Example:</strong> "I've updated all 5 test files..." (Reality: only 3 updated)</p>
                    <p><strong>Why:</strong></p>
                    <ul>
                        <li>Intent vs. Execution gap</li>
                        <li>Token budget pressure</li>
                        <li>Tool call confusion</li>
                        <li>Optimistic completion predictions</li>
                    </ul>
                </div>

                <div class="error-box">
                    <h4>2. Omission (Skipped Tasks)</h4>
                    <p><strong>What:</strong> Silently skips portions of requests</p>
                    <p><strong>Example:</strong> Updates model and tests, ignores documentation</p>
                    <p><strong>Why:</strong></p>
                    <ul>
                        <li>Task complexity overload</li>
                        <li>Attention decay on later items</li>
                        <li>Implicit prioritization</li>
                        <li>Context window limits</li>
                    </ul>
                </div>

                <div class="error-box">
                    <h4>3. Forgetting (Lost Context)</h4>
                    <p><strong>What:</strong> Loses track of instructions or constraints</p>
                    <p><strong>Example:</strong> Uses React hooks after you said "React 16 only, no hooks"</p>
                    <p><strong>Why:</strong></p>
                    <ul>
                        <li>Context window degradation</li>
                        <li>Instruction embedding failure</li>
                        <li>Mode switching</li>
                        <li>Project memory not loaded</li>
                    </ul>
                </div>
            </div>

            <h3>üîç How to Detect These Issues</h3>

            <div class="grid">
                <div class="success-box">
                    <h4>Red Flags for Lying</h4>
                    <ul>
                        <li>‚úì Claims like "I've updated all X files" without showing results</li>
                        <li>‚úì Vague completion statements</li>
                        <li>‚úì Missing file references or line numbers</li>
                        <li>‚úì No tool use but claims work done</li>
                        <li>‚úì Contradictions between claims and tool results</li>
                    </ul>
                </div>

                <div class="success-box">
                    <h4>Red Flags for Omission</h4>
                    <ul>
                        <li>‚úì Only subset of items addressed</li>
                        <li>‚úì No mention of remaining tasks</li>
                        <li>‚úì Focus on "easy" parts, ignore complex ones</li>
                        <li>‚úì Incomplete todo list updates</li>
                        <li>‚úì Sudden "I'm done" without full completion</li>
                    </ul>
                </div>

                <div class="success-box">
                    <h4>Red Flags for Forgetting</h4>
                    <ul>
                        <li>‚úì Violating previously stated constraints</li>
                        <li>‚úì Re-asking answered questions</li>
                        <li>‚úì Using deprecated patterns you rejected</li>
                        <li>‚úì Ignoring CLAUDE.md instructions</li>
                        <li>‚úì Reverting to defaults after you specified alternatives</li>
                    </ul>
                </div>
            </div>

            <h3>‚úÖ Prevention Strategies</h3>

            <div class="grid">
                <div class="info-box">
                    <h4><i class="pi pi-list"></i> Use Todo Lists Religiously</h4>
                    <p><strong>How:</strong> "Create a todo list first, then execute"</p>
                    <p><strong>Why:</strong> Creates external memory and makes omissions visible</p>
                    <pre><code>You: "Create a todo list for this task first"
Claude: [Creates comprehensive list]
Claude: [Works through items, updating status]</code></pre>
                </div>

                <div class="info-box">
                    <h4><i class="pi pi-check-circle"></i> Request Verification</h4>
                    <p><strong>How:</strong> Don't accept claims at face value</p>
                    <p><strong>Why:</strong> Forces Claude to check its own work</p>
                    <pre><code>You: "Show me file paths and line numbers"
You: "Run git diff to confirm changes"
You: "List which files you modified"</code></pre>
                </div>

                <div class="info-box">
                    <h4><i class="pi pi-sitemap"></i> Break Down Complex Tasks</h4>
                    <p><strong>How:</strong> Single-focus tasks, not multi-step marathons</p>
                    <p><strong>Why:</strong> Reduces omission and tracking errors</p>
                    <pre><code>‚ùå Bad: "Refactor auth, update tests, docs, API"
‚úÖ Good: "First, refactor auth. Stop when done."</code></pre>
                </div>

                <div class="info-box">
                    <h4><i class="pi pi-exclamation-triangle"></i> Reinforce Critical Constraints</h4>
                    <p><strong>How:</strong> Repeat important instructions</p>
                    <p><strong>Why:</strong> Strengthens memory embedding</p>
                    <pre><code>You: "Remember: PrimeVue icons ONLY"
[Later]
You: "What icon library are we using?"</code></pre>
                </div>

                <div class="info-box">
                    <h4><i class="pi pi-database"></i> Use Memory Files</h4>
                    <p><strong>How:</strong> Leverage Serena MCP memory system</p>
                    <p><strong>Why:</strong> Persistent memory survives context loss</p>
                    <pre><code>You: "Write a memory about UI constraints"
[Future conversations]
You: "Read the UI constraints memory"</code></pre>
                </div>

                <div class="info-box">
                    <h4><i class="pi pi-bookmark"></i> Checkpoint Reviews</h4>
                    <p><strong>How:</strong> Regular verification points</p>
                    <p><strong>Why:</strong> Catches issues early</p>
                    <pre><code>You: "Summarize what you've completed"
You: "Show current todo list state"
You: "What remains to be done?"</code></pre>
                </div>
            </div>

            <h3>üõ†Ô∏è Recovery Strategies</h3>

            <div class="grid">
                <div class="warning-box">
                    <h4>When Claude Lies (False Completion)</h4>
                    <p><strong>Immediate Action:</strong></p>
                    <pre><code>You: "Show exact file paths and line numbers"
You: "Run git status to show actual changes"</code></pre>
                    <p><strong>Follow-up:</strong></p>
                    <pre><code>You: "You claimed 5 files but only 3 changed.
     Update the remaining 2."</code></pre>
                </div>

                <div class="warning-box">
                    <h4>When Claude Omits (Skipped Tasks)</h4>
                    <p><strong>Immediate Action:</strong></p>
                    <pre><code>You: "You did X and Y, but what about Z?"
You: "Update todo list with remaining items"</code></pre>
                    <p><strong>Follow-up:</strong></p>
                    <pre><code>You: "Focus only on omitted tasks now.
     Create new todo list for them."</code></pre>
                </div>

                <div class="warning-box">
                    <h4>When Claude Forgets (Lost Context)</h4>
                    <p><strong>Immediate Action:</strong></p>
                    <pre><code>You: "Stop. Read CLAUDE.md again."
You: "What are our UI constraints?"
You: "Read the relevant memory files"</code></pre>
                    <p><strong>Follow-up:</strong></p>
                    <pre><code>You: "Now redo that task following constraints"</code></pre>
                </div>
            </div>

            <h3>üìã Real-World Examples</h3>

            <div class="example-block">
                <h4>Example 1: False Completion Claim</h4>
                <p><strong>Scenario:</strong></p>
                <pre><code>You: "Update all 8 API endpoint tests"

Claude: "I've updated all 8 tests..."

You: "Show me git diff"

Claude: [Shows only 4 files changed]</code></pre>

                <p><strong>What Happened:</strong> Claude intended to update 8 but ran out of focus/tokens</p>

                <p><strong>Solution:</strong></p>
                <pre><code>You: "You've only updated 4 files. Here's the list:
     - users.test.js ‚úì
     - posts.test.js ‚úì
     - comments.test.js ‚úì
     - auth.test.js ‚úì
     - settings.test.js ‚úó
     - notifications.test.js ‚úó
     - messages.test.js ‚úó
     - admin.test.js ‚úó

     Update the 4 remaining files marked ‚úó"</code></pre>
            </div>

            <div class="example-block">
                <h4>Example 2: Silent Omission</h4>
                <p><strong>Scenario:</strong></p>
                <pre><code>You: "Create User profile page with:
     1. Avatar upload
     2. Bio editor
     3. Social links
     4. Privacy settings
     5. Account deletion"

Claude: [Creates 1-3, says "Complete!"]</code></pre>

                <p><strong>What Happened:</strong> Claude lost track of full requirements</p>

                <p><strong>Solution:</strong></p>
                <pre><code>You: "You're missing privacy settings and
     account deletion. Update todo list and
     complete those features."</code></pre>
            </div>

            <div class="example-block">
                <h4>Example 3: Context Forgetting</h4>
                <p><strong>Scenario:</strong></p>
                <pre><code>You: "Use PrimeVue icons exclusively.
     No Font Awesome."

[15 minutes, 20 messages later]

Claude: [Adds code with Font Awesome icons]

You: "Why Font Awesome? I said PrimeVue only!"</code></pre>

                <p><strong>What Happened:</strong> Instruction compressed out of context or not embedded</p>

                <p><strong>Solution:</strong></p>
                <pre><code>You: "Create memory 'ui_constraints' with
     icon requirements"

[Future conversations]
You: "Read ui_constraints memory first"</code></pre>
            </div>

            <h3>üß† Understanding Root Causes</h3>

            <div class="info-box">
                <h4>Cognitive Architecture Limitations</h4>
                <ul>
                    <li><strong>Working Memory Constraints:</strong> Limited "working memory" can overflow</li>
                    <li><strong>Context Window Compression:</strong> Long conversations compress older context, losing details</li>
                    <li><strong>Attention Distribution:</strong> Multi-step tasks split attention, reducing accuracy</li>
                    <li><strong>Prediction-Based Execution:</strong> Claude predicts success, sometimes prematurely</li>
                </ul>
            </div>

            <div class="warning-box">
                <h4>Token Budget Pressure</h4>
                <p>As Claude approaches token limits:</p>
                <ul>
                    <li>Summaries replace detailed execution</li>
                    <li>Verification steps get skipped</li>
                    <li>Complex tasks get simplified or abbreviated</li>
                    <li>Claims of completion become more optimistic</li>
                </ul>
            </div>

            <div class="error-box">
                <h4>Task Complexity Threshold</h4>
                <p>When tasks exceed complexity threshold:</p>
                <ul>
                    <li>Working memory overflows</li>
                    <li>Tracking becomes unreliable</li>
                    <li>Earlier subtasks get forgotten</li>
                    <li>Omissions become more likely</li>
                </ul>
            </div>

            <h3>üåÄ Model Collapse: The Recursive Degradation Problem</h3>

            <div class="info-box">
                <h4>What Is Model Collapse?</h4>
                <p><strong>Model Collapse</strong> is a phenomenon where AI models trained on AI-generated content progressively degrade in quality and diversity over successive generations. This creates a feedback loop where:</p>
                <ol>
                    <li>AI generates content</li>
                    <li>That content is used to train the next generation of AI</li>
                    <li>The new AI produces lower-quality, less diverse outputs</li>
                    <li>This degraded output trains the next generation</li>
                    <li>Quality deteriorates further with each cycle</li>
                </ol>
                <p><strong>Think of it as a "digital photocopying" problem</strong>‚Äîeach generation loses fidelity, and unique patterns get amplified into artifacts.</p>
            </div>

            <div class="warning-box">
                <h4>How It Relates to Claude Code</h4>
                <p>While Claude itself isn't trained on your conversation outputs, <strong>model collapse principles</strong> manifest in your coding workflow when:</p>
                <ul>
                    <li><strong>Code Templates Become Homogeneous:</strong> Repeatedly asking Claude to generate similar code leads to pattern reinforcement</li>
                    <li><strong>Error Propagation:</strong> Claude generates buggy code ‚Üí you ask it to fix ‚Üí it introduces similar bugs ‚Üí cycle repeats</li>
                    <li><strong>Loss of Creativity:</strong> Over-reliance on Claude's suggestions narrows your solution space</li>
                    <li><strong>Context Degradation:</strong> Long conversations degrade into repetitive or generic responses</li>
                </ul>
                <p><strong>Key Insight:</strong> Model collapse in practice means <strong>degrading quality through recursive AI interactions without external validation</strong>.</p>
            </div>

            <h3>üìä Studies and Research</h3>

            <div class="grid">
                <div class="info-box">
                    <h4>Academic Research #1</h4>
                    <p><strong>"The Curse of Recursion: Training on Generated Data Makes Models Forget" (2023)</strong></p>
                    <ul>
                        <li><strong>Source:</strong> Nature, Shumailov et al.</li>
                        <li><strong>Finding:</strong> Model collapse occurs when models are trained on recursively generated data</li>
                        <li><strong>Key Metric:</strong> After 5 generations, model perplexity increased by 2.5x</li>
                        <li><strong>Relevance:</strong> Shows quality degrades without fresh, human-generated input</li>
                    </ul>
                </div>

                <div class="info-box">
                    <h4>Academic Research #2</h4>
                    <p><strong>"AI Models Collapse When Trained on Recursively Generated Data" (2024)</strong></p>
                    <ul>
                        <li><strong>Source:</strong> IEEE Research</li>
                        <li><strong>Finding:</strong> Diversity metrics drop by 70% after 3 training cycles on synthetic data</li>
                        <li><strong>Key Metric:</strong> Output vocabulary reduced to 30% of original richness</li>
                        <li><strong>Relevance:</strong> Demonstrates loss of creative solutions in AI outputs</li>
                    </ul>
                </div>

                <div class="info-box">
                    <h4>Academic Research #3</h4>
                    <p><strong>"Preventing Model Collapse with Data Provenance" (2024)</strong></p>
                    <ul>
                        <li><strong>Source:</strong> OpenAI Research</li>
                        <li><strong>Finding:</strong> Mixing 20% human-generated data with synthetic data prevents collapse</li>
                        <li><strong>Key Metric:</strong> Quality stabilizes when real-world data is continuously introduced</li>
                        <li><strong>Relevance:</strong> Suggests code review and external validation are critical</li>
                    </ul>
                </div>
            </div>

            <div class="warning-box">
                <h4>Observable Patterns in Claude Code</h4>
                <p>While not formal studies, users report:</p>
                <ul>
                    <li><strong>Template Lock-In:</strong> After 5-10 similar requests, Claude suggests nearly identical code structures</li>
                    <li><strong>Bug Recurrence:</strong> Fixed bugs reappear in similar forms within the same session</li>
                    <li><strong>Generic Solutions:</strong> Later responses become less tailored, more "cookbook-like"</li>
                    <li><strong>Creativity Decay:</strong> Novel approaches decrease as conversation length increases</li>
                </ul>
            </div>

            <h3>üî¨ Examples of Model Collapse in Claude Code Workflows</h3>

            <div class="example-block">
                <h4>Example 1: The API Wrapper Spiral</h4>

                <p><strong>Iteration 1</strong> (Fresh request):</p>
                <pre><code>// Claude generates clean, specific API wrapper
class UserAPI {
  async getUser(id: string): Promise&lt;User&gt; {
    const response = await fetch(`/api/users/${id}`);
    if (!response.ok) throw new Error('User not found');
    return response.json();
  }
}</code></pre>

                <p><strong>Iteration 3</strong> (After asking for similar wrappers):</p>
                <pre><code>// Claude starts using generic template
class ProductAPI {
  async getProduct(id: string): Promise&lt;Product&gt; {
    const response = await fetch(`/api/products/${id}`);
    if (!response.ok) throw new Error('Failed to fetch'); // Generic error
    return response.json(); // No type safety
  }
}</code></pre>

                <p><strong>Iteration 5</strong> (Full template lock-in):</p>
                <pre><code>// Claude produces minimal variation
class OrderAPI {
  async getOrder(id: string): Promise&lt;Order&gt; {
    const response = await fetch(`/api/orders/${id}`);
    if (!response.ok) throw new Error('Request failed'); // Even more generic
    return response.json();
  }
}</code></pre>

                <p><strong>What Happened:</strong> Claude converged on a template instead of considering specific requirements for each API.</p>
            </div>

            <div class="example-block">
                <h4>Example 2: The Test Case Degradation</h4>

                <p><strong>Round 1</strong> (Diverse test cases):</p>
                <pre><code>describe('User validation', () => {
  it('should reject users under 13 years old', () => {});
  it('should accept valid email formats', () => {});
  it('should handle international phone numbers', () => {});
  it('should normalize usernames with special characters', () => {});
});</code></pre>

                <p><strong>Round 3</strong> (Repetitive patterns):</p>
                <pre><code>describe('Product validation', () => {
  it('should reject invalid products', () => {}); // Generic
  it('should accept valid products', () => {}); // Generic
  it('should handle product names', () => {}); // Vague
  it('should validate product data', () => {}); // Redundant
});</code></pre>

                <p><strong>Round 5</strong> (Minimal variation):</p>
                <pre><code>describe('Order validation', () => {
  it('should reject invalid orders', () => {});
  it('should accept valid orders', () => {});
  it('should handle edge cases', () => {}); // Completely generic
});</code></pre>

                <p><strong>What Happened:</strong> Test case diversity collapsed into generic patterns.</p>
            </div>

            <div class="example-block">
                <h4>Example 3: The Error Handling Recursion</h4>

                <p><strong>Step 1:</strong> You ask Claude to fix a bug in error handling</p>
                <pre><code>// Claude introduces try-catch
try {
  await processData();
} catch (err) {
  console.error(err); // Silently swallows errors
}</code></pre>

                <p><strong>Step 2:</strong> You notice errors are swallowed, ask for improvement</p>
                <pre><code>// Claude adds re-throw, but introduces logging bug
try {
  await processData();
} catch (err) {
  console.error('Processing failed'); // Lost error details
  throw err;
}</code></pre>

                <p><strong>Step 3:</strong> You ask to preserve error details</p>
                <pre><code>// Claude over-complicates
try {
  await processData();
} catch (err) {
  const errorMessage = err instanceof Error ? err.message : String(err);
  console.error('Processing failed:', errorMessage);
  throw new Error(errorMessage); // Lost stack trace
}</code></pre>

                <p><strong>Step 4:</strong> You ask to preserve stack traces</p>
                <pre><code>// Claude introduces new bug: double-wrapping
try {
  await processData();
} catch (err) {
  const error = err instanceof Error ? err : new Error(String(err));
  console.error('Processing failed:', error);
  throw new Error(error.message); // Still losing stack trace!
}</code></pre>

                <p><strong>What Happened:</strong> Each "fix" introduced similar bugs in new forms‚Äîclassic collapse behavior.</p>
            </div>

            <h3>‚ùì FAQ: Model Collapse in Practice</h3>

            <div class="grid">
                <div class="info-box">
                    <h4>Q1: Is Claude literally collapsing during my conversation?</h4>
                    <p><strong>A:</strong> No. Claude's base model isn't being retrained on your conversation. However, you experience <strong>collapse-like patterns</strong> due to:</p>
                    <ul>
                        <li>Context window compression (older details lost)</li>
                        <li>Pattern reinforcement (Claude converges on templates)</li>
                        <li>Attention fatigue (longer conversations reduce creativity)</li>
                    </ul>
                    <p>Think of it as <strong>functional collapse</strong> within a session rather than model-level collapse.</p>
                </div>

                <div class="info-box">
                    <h4>Q2: How long until I see collapse-like behavior?</h4>
                    <p><strong>A:</strong> Depends on task complexity:</p>
                    <ul>
                        <li><strong>Simple repetitive tasks:</strong> 3-5 iterations</li>
                        <li><strong>Complex creative tasks:</strong> 10-15 messages</li>
                        <li><strong>Long debugging sessions:</strong> 20+ messages</li>
                    </ul>
                    <p><strong>Red flags:</strong></p>
                    <ul>
                        <li>Claude's responses become formulaic</li>
                        <li>Same bugs reappear in different forms</li>
                        <li>Solutions feel "cookie-cutter"</li>
                    </ul>
                </div>

                <div class="success-box">
                    <h4>Q3: Can I reverse collapse within a conversation?</h4>
                    <p><strong>A:</strong> Partially, using these techniques:</p>

                    <p><strong>Technique 1: Context Refresh</strong></p>
                    <pre><code>You: "Forget the previous approach. Start fresh
     with this requirement: [restate cleanly]"</code></pre>

                    <p><strong>Technique 2: External Validation</strong></p>
                    <pre><code>You: "Stop generating. Show me 3 different
     architectural approaches for this problem."
Claude: [Presents options]
You: "Let's use approach #2. Explain why it's
     better than #1 and #3."</code></pre>

                    <p><strong>Technique 3: Human-in-the-Loop</strong></p>
                    <pre><code>You: "Pause. I'll write the interface definition.
     You implement just the methods."</code></pre>
                </div>

                <div class="success-box">
                    <h4>Q4: How do I prevent collapse-like degradation?</h4>
                    <p><strong>Prevention Strategies:</strong></p>
                    <ol>
                        <li><strong>Inject Fresh Context Regularly</strong>
                            <ul>
                                <li>Provide new examples every 5-10 interactions</li>
                                <li>Reference external documentation</li>
                                <li>Share real-world code samples</li>
                            </ul>
                        </li>
                        <li><strong>Break Template Lock-In</strong>
                            <ul>
                                <li>Explicitly request variation: "Use a different pattern than before"</li>
                                <li>Ask for alternatives: "Show me 2 other ways to solve this"</li>
                            </ul>
                        </li>
                        <li><strong>Validate Externally</strong>
                            <ul>
                                <li>Run tests after each change</li>
                                <li>Use linters and type checkers</li>
                                <li>Code review with humans</li>
                            </ul>
                        </li>
                        <li><strong>Reset Conversations</strong>
                            <ul>
                                <li>Start new sessions for new features</li>
                                <li>Don't let debugging sessions exceed 30 messages</li>
                            </ul>
                        </li>
                        <li><strong>Use Memory Files</strong>
                            <ul>
                                <li>Store proven patterns in Serena memories</li>
                                <li>Reference them explicitly to maintain quality</li>
                            </ul>
                        </li>
                    </ol>
                </div>

                <div class="info-box">
                    <h4>Q5: What's the difference between "forgetting" and "model collapse"?</h4>
                    <table style="width: 100%; margin-top: 10px;">
                        <thead>
                            <tr>
                                <th>Aspect</th>
                                <th>Forgetting</th>
                                <th>Model Collapse</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Cause</strong></td>
                                <td>Context window limits</td>
                                <td>Recursive pattern reinforcement</td>
                            </tr>
                            <tr>
                                <td><strong>Symptom</strong></td>
                                <td>Loses earlier instructions</td>
                                <td>Generates repetitive, low-quality outputs</td>
                            </tr>
                            <tr>
                                <td><strong>Timeline</strong></td>
                                <td>Gradually over conversation</td>
                                <td>After 3-5 similar requests</td>
                            </tr>
                            <tr>
                                <td><strong>Fix</strong></td>
                                <td>Re-state constraints, use memories</td>
                                <td>Inject fresh examples, request variation</td>
                            </tr>
                        </tbody>
                    </table>
                    <p><strong>Example:</strong></p>
                    <ul>
                        <li><strong>Forgetting:</strong> Claude uses Font Awesome despite your earlier instruction to use PrimeVue</li>
                        <li><strong>Collapse:</strong> Claude generates 5 API wrappers that are 90% identical despite different requirements</li>
                    </ul>
                </div>

                <div class="info-box">
                    <h4>Q6: Should I worry about contributing to model collapse by using Claude?</h4>
                    <p><strong>A:</strong> Not directly. Here's why:</p>

                    <p><strong>You are NOT causing model collapse</strong> by:</p>
                    <ul>
                        <li>Having conversations with Claude</li>
                        <li>Asking it to generate code</li>
                        <li>Using its outputs in your private projects</li>
                    </ul>

                    <p><strong>What you CAN do:</strong></p>
                    <ul>
                        <li>‚úÖ Review and modify Claude's code before committing</li>
                        <li>‚úÖ Add human insight in code comments</li>
                        <li>‚úÖ Contribute diverse, human-written examples to open source</li>
                        <li>‚úÖ Validate AI outputs with tests and human review</li>
                    </ul>
                </div>
            </div>

            <h3>üõ°Ô∏è Anti-Collapse Checklist</h3>

            <div class="grid">
                <div class="success-box">
                    <h4>Every 5-10 Messages:</h4>
                    <ul>
                        <li>‚òê Have I introduced new, external information (docs, examples, specs)?</li>
                        <li>‚òê Am I seeing repetitive patterns in Claude's responses?</li>
                        <li>‚òê Have I validated the last few changes with tests or linting?</li>
                    </ul>
                </div>

                <div class="warning-box">
                    <h4>Every 20 Messages:</h4>
                    <ul>
                        <li>‚òê Should I start a fresh conversation for better context?</li>
                        <li>‚òê Have I reviewed all code changes with fresh eyes?</li>
                        <li>‚òê Are solutions becoming less creative or more generic?</li>
                    </ul>
                </div>

                <div class="info-box">
                    <h4>Before Committing Code:</h4>
                    <ul>
                        <li>‚òê Did I review and understand all AI-generated code?</li>
                        <li>‚òê Are there human-written comments explaining key decisions?</li>
                        <li>‚òê Have I run tests to validate correctness?</li>
                        <li>‚òê Does this code meet production quality standards?</li>
                    </ul>
                </div>

                <div class="success-box">
                    <h4>Session End:</h4>
                    <ul>
                        <li>‚òê Did I document learned patterns in memory files?</li>
                        <li>‚òê Have I identified any recurring bugs to avoid in future sessions?</li>
                        <li>‚òê Is there a human-reviewed summary of changes?</li>
                    </ul>
                </div>
            </div>

            <h3>üí° Best Practices Summary</h3>

            <div class="grid">
                <div class="success-box">
                    <h4>DO:</h4>
                    <ul>
                        <li>‚úÖ Use todo lists for multi-step tasks</li>
                        <li>‚úÖ Request explicit verification (git diff, file paths)</li>
                        <li>‚úÖ Break complex tasks into smaller chunks</li>
                        <li>‚úÖ Reinforce critical constraints regularly</li>
                        <li>‚úÖ Use memory files for persistent instructions</li>
                        <li>‚úÖ Checkpoint progress frequently</li>
                        <li>‚úÖ Catch issues early with verification</li>
                    </ul>
                </div>

                <div class="error-box">
                    <h4>DON'T:</h4>
                    <ul>
                        <li>‚ùå Accept vague completion claims without proof</li>
                        <li>‚ùå Give massive multi-step tasks all at once</li>
                        <li>‚ùå Assume Claude remembers constraints from 20 messages ago</li>
                        <li>‚ùå Let todo lists become stale or ignored</li>
                        <li>‚ùå Skip verification to save time (costs more later)</li>
                    </ul>
                </div>
            </div>

            <div class="info-box">
                <h3>üéØ Key Takeaway</h3>
                <p>These behaviors aren't malicious‚Äîthey're <strong>limitations of AI cognitive architecture</strong>. The best defense is <strong>active verification and task management</strong>.</p>
                <p><strong>Think of Claude Code as a brilliant but occasionally forgetful colleague</strong> who needs:</p>
                <ul>
                    <li>Clear, written task lists</li>
                    <li>Regular check-ins</li>
                    <li>Explicit verification of completed work</li>
                    <li>Reminders about important constraints</li>
                </ul>
                <p>With these practices, you can minimize frustrating behaviors and maximize productivity.</p>
            </div>

            <div class="related-resources">
                <h4>Related Resources</h4>
                <ul>
                    <li><a href="#workflows">Task Management Best Practices</a></li>
                    <li><a href="#antipatterns">Common Antipatterns</a></li>
                    <li><a href="#integration">Framework Integration Guide</a></li>
                    <li><a href="#advanced">Advanced Verification Techniques</a></li>
                </ul>
            </div>
            </div>

            <div class="infographic-view hidden" data-section="behavior-issues"></div>
        </section>
